{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/media/crocoder/New Volume/Personal/Projects/Task-4/ReCAM\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.concat_dataset import ConcatDataset"
   ]
  },
  {
   "source": [
    "from src.utils.configuration import Config"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = Config(path= './configs/datasets/concat/bert_answer_attention.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Config(dic={'name': 'concat', 'data_dir': './data/train/', 'truncate_length': 512, 'preprocessor': {'name': 'transformersPreprocessor', 'tokenizer': {'name': 'AutoTokenizer', 'init_params': {'pretrained_model_name_or_path': 'bert-base-uncased'}}}, 'file_path': './data/train/Task_1_train.jsonl', 'split': 'train'})"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data_config.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.mapper import configmapper\n",
    "from src.modules.tokenizers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = configmapper.get_object(\"tokenizers\",data_config.train.preprocessor.tokenizer.name).from_pretrained(**data_config.train.preprocessor.tokenizer.init_params.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "tok2 = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = ConcatDataset(data_config.train, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dat, batch_size=4,shuffle=True, collate_fn=dat.custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['concats_token_ids', 'concats_token_type_ids', 'answer_indices', 'concats_attention_masks', 'options_indices', 'options_attention_masks'])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "sample[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 493])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "sample[0]['concats_token_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 493])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "sample[0]['concats_token_type_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([376, 458, 454, 462])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "sample[0]['answer_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 493])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "sample[0]['concats_attention_masks'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[384],\n",
       "         [386],\n",
       "         [388],\n",
       "         [390],\n",
       "         [392]],\n",
       "\n",
       "        [[464],\n",
       "         [466],\n",
       "         [468],\n",
       "         [470],\n",
       "         [472]],\n",
       "\n",
       "        [[483],\n",
       "         [485],\n",
       "         [487],\n",
       "         [489],\n",
       "         [491]],\n",
       "\n",
       "        [[474],\n",
       "         [476],\n",
       "         [478],\n",
       "         [480],\n",
       "         [482]]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "sample[0]['options_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]],\n",
       "\n",
       "        [[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]],\n",
       "\n",
       "        [[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]],\n",
       "\n",
       "        [[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "sample[0]['options_attention_masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig, BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        nn.init.kaiming_normal_(self.linear.weight.data)\n",
    "        nn.init.constant_(self.linear.bias.data, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x: [batch_size, seq_len, in_features]\n",
    "        x = self.linear(x)\n",
    "        # x: [batch_size, seq_len, out_features]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAttentionLogits(nn.Module):\n",
    "    def __init__(self, dim, dropout):\n",
    "        super(MLPAttentionLogits, self).__init__()\n",
    "\n",
    "        self.Q_W = Linear(dim, dim)\n",
    "        self.K_W = Linear(dim, dim)\n",
    "        self.V_W = Linear(dim, dim)\n",
    "\n",
    "        self.linear = Linear(dim, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        # Q: [batch_size, dim]\n",
    "        # K: [batch_size, seq_len, dim]\n",
    "        # V: [batch_size, seq_len, dim]\n",
    "\n",
    "        Q = self.dropout(self.Q_W(Q))  # [batch_size, dim]\n",
    "        K = self.dropout(self.K_W(K))  # [batch_size, seq_len, dim]\n",
    "        V = self.dropout(self.V_W(V))  # [batch_size, seq_len, dim]\n",
    "\n",
    "        Q = Q.unsqueeze(1)  # [batch_size, 1, dim]\n",
    "        M = self.dropout(Q * K)  # [batch_size, seq_len, dim]\n",
    "        scores = self.dropout(self.linear(M))  # [batch_size, seq_len, 1]\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerAttentionBert(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AnswerAttentionBert, self).__init__()\n",
    "        self.config = config\n",
    "        self.bert = BertModel.from_pretrained(self.config.bert_pretrained_name)\n",
    "        self.attention = MLPAttentionLogits(self.config.hidden_size, self.config.dropout)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        concats_token_ids = batch[\"concats_token_ids\"]  # [batch_size,seq_length]\n",
    "        concats_token_type_ids = batch[\n",
    "            \"concats_token_type_ids\"\n",
    "        ]  # [batch_size, seq_length]\n",
    "        answer_indices = batch[\"answer_indices\"]  # [batch_size,]\n",
    "        concats_attention_masks = batch[\n",
    "            \"concats_attention_masks\"\n",
    "        ]  # [batch_size, seq_length]\n",
    "        options_indices = batch[\n",
    "            \"options_indices\"\n",
    "        ]  # [batch_size, 5, max_options_length] May be padded using 1000000\n",
    "        options_attention_masks = batch[\"options_attention_masks\"] # [batch_size, 5, max_options_length]\n",
    "\n",
    "        concat_embeddings = self.bert(\n",
    "            input_ids = concats_token_ids,\n",
    "            attention_mask = concats_attention_masks,\n",
    "            token_type_ids=concats_token_type_ids,\n",
    "        )[0]  # [batch_size, seq_length, hidden_size]\n",
    "\n",
    "        batch_size = answer_indices.shape[0]\n",
    "        hidden_size = concat_embeddings.shape[-1]\n",
    "        answer_indices = answer_indices.reshape(-1, 1, 1).expand(\n",
    "            batch_size, 1, hidden_size\n",
    "        )  # [batch_size, 1, hidden_size]\n",
    "        mask_embedding = torch.gather(\n",
    "            concat_embeddings, 1, answer_indices\n",
    "        )  # [batch_size,1,768]\n",
    "\n",
    "        tokens_per_option_per_batch = torch.sum(options_attention_masks,dim=2) ##[batch_size,5]\n",
    "\n",
    "        ops_avg_embeddings = []\n",
    "\n",
    "        for i in range(5):\n",
    "            ops_i_indices = options_indices[:,i,:] ## [batch_size,max_options_length]\n",
    "            ops_i_indices = ops_i_indices.reshape(batch_size,-1,1).expand(batch_size,-1,hidden_size) ##[batch_size,max_options_length,hidden_size]\n",
    "            ops_i_masks = options_attention_masks[:,i,:].reshape(batch_size,-1,1).expand(batch_size,-1,hidden_size) ##[batch_size,max_options_length,hidden_size]\n",
    "            ops_i_embeddings = torch.gather(concat_embeddings, 1,ops_i_indices) ## [batch_size,max_options_length,hidden_size]\n",
    "            ops_i_embeddings = ops_i_masks*ops_i_embeddings ## [batch_size,max_options_length,hidden_size]\n",
    "            ops_i_avg_embeddings = torch.sum(ops_i_embeddings,dim=1)/tokens_per_option_per_batch[:,i].reshape(-1,1).expand(-1,hidden_size) ##[batch_size,hidden_size]\n",
    "            ops_avg_embeddings.append(ops_i_avg_embeddings.unsqueeze(1))\n",
    "        ops_avg_embeddings = torch.cat(ops_avg_embeddings,dim=1)\n",
    "\n",
    "        out_logits = self.attention(mask_embedding.squeeze(), ops_avg_embeddings, ops_avg_embeddings).squeeze()\n",
    "\n",
    "        return out_logits   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'bert_pretrained_name':'bert-base-uncased',\n",
    "    'num_labels': 5,\n",
    "    'hidden_size': 768,\n",
    "    'dropout':0.2,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = Config(dic=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "aab = AnswerAttentionBert(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.4213, -0.0611,  0.4953, -0.2289,  0.0000],\n",
       "        [-0.2388,  0.3919,  0.4119, -0.4489, -0.0000],\n",
       "        [-0.2882, -0.0000, -1.2821,  0.9153,  0.0890],\n",
       "        [-0.3784,  0.0237, -0.5242, -0.8572,  0.1734]],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "aab(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}