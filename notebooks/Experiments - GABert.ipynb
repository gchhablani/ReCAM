{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_1_FILE = '../data/train/Task_1_train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_1_FILE,'r') as f:\n",
    "    lines = [json.loads(line) for line in f.read().splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "bt = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "article_token = bt.encode(example['article'])[:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_token = bt.encode(example['question'].replace('@placeholder','[MASK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_tokens = [bt.encode(example[f'option_{i}']) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_token = torch.LongTensor([article_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_token = torch.LongTensor([question_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_tokens = torch.LongTensor(options_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "m = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.embeddings(article_token).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.embeddings(question_token).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.embeddings(options_tokens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "m2 = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = m1.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_1 = m1.encoder.layer[0]\n",
    "layer_2_1 = m2.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "article_embeds = e1(article_token)\n",
    "print(article_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 26, 768])\n"
     ]
    }
   ],
   "source": [
    "question_embeds = e1(question_token)\n",
    "print(question_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "options_embeds = e1(options_tokens)\n",
    "print(options_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedAttention(torch.nn.Module):      \n",
    "    def forward(self, question_states, article_states):\n",
    "        question_att = question_states.permute(0,2,1)\n",
    "        att_matrix = torch.bmm(article_states,question_att)\n",
    "        \n",
    "        att_weights = torch.nn.functional.softmax(att_matrix.view(-1,att_matrix.size(-1)),dim=1).view_as(att_matrix)\n",
    "        question_rep = torch.bmm(att_weights, question_states)\n",
    "    \n",
    "        question_to_article = torch.mul(article_states, question_rep)\n",
    "        \n",
    "        return question_to_article ##Attention applied on articles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GatedAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_1_out = layer_1_1(question_embeds)\n",
    "layer_2_1_out = layer_2_1(article_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1_1_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2_1_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga(layer_1_1_out[0],layer_2_1_out[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1 = question_embeds\n",
    "inp_2 = article_embeds\n",
    "\n",
    "## Need to check attention_mask and layer_head_mask\n",
    "for i in range(len(m1.encoder.layer)):\n",
    "    current_layer_1 = m1.encoder.layer[i]\n",
    "    current_layer_2 = m2.encoder.layer[i]\n",
    "    inp_1 = current_layer_1(inp_1)[0]\n",
    "    int_2 = current_layer_2(inp_2)[0]\n",
    "    inp_2 = ga(inp_1,int_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.1008e-02,  8.4509e-02,  9.0809e-02,  ..., -2.0987e-02,\n",
       "           2.0178e-02,  1.3246e-01],\n",
       "         [ 7.2911e-02,  5.7018e-02,  7.9535e-02,  ..., -1.7414e-02,\n",
       "           4.2224e-02,  1.2953e-01],\n",
       "         [ 6.1251e-02,  2.1614e-02,  7.0671e-02,  ..., -8.3078e-03,\n",
       "           6.3368e-02,  1.2328e-01],\n",
       "         ...,\n",
       "         [ 5.1315e-02, -4.3455e-01, -1.0332e-01,  ...,  2.9795e-02,\n",
       "          -5.7426e-02, -1.7541e-04],\n",
       "         [ 2.6858e-02, -4.4956e-01, -1.2668e-01,  ...,  5.7979e-02,\n",
       "          -2.2074e-01, -4.7746e-02],\n",
       "         [-1.1459e-01,  3.6559e-02, -1.0911e-01,  ..., -6.2565e-02,\n",
       "          -1.8362e-01,  7.9108e-02]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "         [-0.4367,  0.5360, -0.0514,  ..., -0.0397,  0.6783, -0.5318],\n",
       "         [ 0.7838, -0.3506, -1.1582,  ..., -0.8033,  0.1465,  0.2171],\n",
       "         ...,\n",
       "         [ 0.2022,  0.0762,  0.3220,  ...,  0.5130, -0.6300, -0.0597],\n",
       "         [ 1.3539,  0.4626,  0.3129,  ..., -0.9238, -0.9422, -0.4833],\n",
       "         [ 0.7480,  0.4874, -0.3261,  ..., -0.5679,  0.9606, -1.7922]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertEmbeddings(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = BertModel.from_pretrained('bert-base-uncased').embeddings\n",
    "    \n",
    "    def forward(self, article_tokens, question_tokens, options_tokens):\n",
    "        article_embeds = self.embeddings(article_tokens)\n",
    "        question_embeds = self.embeddings(question_tokens)\n",
    "        options_embeds = self.embeddings(options_tokens)\n",
    "    \n",
    "        return article_embeds, question_embeds, options_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GABertEmbeddings()\n",
    "article_embeds, question_embeds, options_embeds = embeddings(article_token,question_token, options_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertEncoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.m2 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.ga = GatedAttention()\n",
    "        \n",
    "    def forward(self, article_contexts, question_contexts, article_attention_mask=None, question_attention_mask=None):\n",
    "        \n",
    "        for i in range(len(self.m1.encoder.layer)):\n",
    "            current_layer_1 = self.m1.encoder.layer[i]\n",
    "            current_layer_2 = self.m2.encoder.layer[i]\n",
    "            question_contexts = current_layer_1(question_contexts, question_attention_mask)[0]\n",
    "            article_intermediates = current_layer_2(article_contexts, article_attention_mask)[0]\n",
    "            article_contexts = ga(question_contexts,article_intermediates)\n",
    "        \n",
    "        return article_contexts, question_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GABertEncoder()\n",
    "article_contexts, question_contexts= encoder(article_embeds, question_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertPooler(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pooler = BertModel.from_pretrained('bert-base-uncased').pooler\n",
    "    def forward(self,contexts):\n",
    "        return self.pooler(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Layer Out (Baseline GAReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        torch.nn.init.kaiming_normal_(self.linear.weight.data)\n",
    "        torch.nn.init.constant_(self.linear.bias.data, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x: [batch_size, seq_len, in_features]\n",
    "        x = self.linear(x)\n",
    "        # x: [batch_size, seq_len, out_features]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAttention(torch.nn.Module):\n",
    "    def __init__(self, dim, dropout):\n",
    "        super(MLPAttention, self).__init__()\n",
    "\n",
    "        self.Q_W = Linear(dim, dim)\n",
    "        self.K_W = Linear(dim, dim)\n",
    "        self.V_W = Linear(dim, dim)\n",
    "\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.V = Linear(dim, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        # Q: [batch_size, dim]\n",
    "        # K: [batch_size, seq_len, dim]\n",
    "        # V: [batch_size, seq_len, dim]\n",
    "\n",
    "        Q = self.dropout(self.Q_W(Q))  # [batch_size, dim]\n",
    "        K = self.dropout(self.K_W(K))  # [batch_size, seq_len, dim]\n",
    "        V = self.dropout(self.V_W(V))  # [batch_size, seq_len, dim]\n",
    "\n",
    "        Q = Q.unsqueeze(1)  # [batch_size, 1, dim]\n",
    "        M = self.dropout(self.tanh(Q + K))  # [batch_size, seq_len, dim]\n",
    "        scores = self.dropout(self.V(M))  # [batch_size, seq_len, 1]\n",
    "        scores = F.softmax(scores, dim=1)  # [batch_size, seq_len, 1]\n",
    "\n",
    "        R = self.dropout(V * scores)  # [batch_size, seq_len, dim]\n",
    "\n",
    "        feat = torch.sum(R, dim=1)  # [batch_size, dim]\n",
    "\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineOut(torch.nn.Module):\n",
    "    def __init__(dropout, hidden_size):\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.mlp_att = MLPAttention(hidden_size*2, dropout)\n",
    "        self.dot_layer = MLPAttention(hidden_size*2,dropout)\n",
    "        self.final_linear = Linear(hidden_size*10,output_dim)\n",
    "    def forward(self, article_contexts,question_contexts,options_embeds):\n",
    "\n",
    "        bsz = article_contexts.shape[0]\n",
    "        options_embeds = options_embeds.view(bsz,5,-1,hidden_size)\n",
    "        \n",
    "        article_question_attention = self.mlp_att(question_contexts, article_contexts, article_contexts)\n",
    "        \n",
    "        \n",
    "        att_opt0 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection and Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
