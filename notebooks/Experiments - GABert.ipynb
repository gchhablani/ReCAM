{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_1_FILE = '../data/train/Task_1_train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_1_FILE,'r') as f:\n",
    "    lines = [json.loads(line) for line in f.read().splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "bt = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_token = bt.encode(example['article'])[:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_token = bt.encode(example['question'].replace('@placeholder','[MASK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_tokens = [bt.encode(example[f'option_{i}']) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_token = torch.LongTensor([article_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_token = torch.LongTensor([question_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_tokens = torch.LongTensor(options_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "m = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.embeddings(article_token).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 768])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.embeddings(question_token).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 768])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.embeddings(options_tokens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "m2 = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = m1.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_1 = m1.encoder.layer[0]\n",
    "layer_2_1 = m2.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "article_embeds = e1(article_token)\n",
    "print(article_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 26, 768])\n"
     ]
    }
   ],
   "source": [
    "question_embeds = e1(question_token)\n",
    "print(question_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "options_embeds = e1(options_tokens)\n",
    "print(options_tokensembeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedAttention(torch.nn.Module):      \n",
    "    def forward(self, question_states, article_states):\n",
    "        question_att = question_states.permute(0,2,1)\n",
    "        att_matrix = torch.bmm(article_states,question_att)\n",
    "        \n",
    "        att_weights = torch.nn.functional.softmax(att_matrix.view(-1,att_matrix.size(-1)),dim=1).view_as(att_matrix)\n",
    "        question_rep = torch.bmm(att_weights, question_states)\n",
    "    \n",
    "        question_to_article = torch.mul(article_states, question_rep)\n",
    "        \n",
    "        return question_to_article ##Attention applied on articles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GatedAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_1_out = layer_1_1(question_embeds)\n",
    "layer_2_1_out = layer_2_1(article_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 768])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1_1_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2_1_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga(layer_1_1_out[0],layer_2_1_out[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1 = question_embeds\n",
    "inp_2 = article_embeds\n",
    "\n",
    "## Need to check attention_mask and layer_head_mask\n",
    "for i in range(len(m1.encoder.layer)):\n",
    "    current_layer_1 = m1.encoder.layer[i]\n",
    "    current_layer_2 = m2.encoder.layer[i]\n",
    "    inp_1 = current_layer_1(inp_1)[0]\n",
    "    int_2 = current_layer_2(inp_2)[0]\n",
    "    inp_2 = ga(inp_1,int_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 768])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.1008e-02,  8.4509e-02,  9.0809e-02,  ..., -2.0987e-02,\n",
       "           2.0178e-02,  1.3246e-01],\n",
       "         [ 7.2911e-02,  5.7018e-02,  7.9535e-02,  ..., -1.7414e-02,\n",
       "           4.2224e-02,  1.2953e-01],\n",
       "         [ 6.1251e-02,  2.1614e-02,  7.0671e-02,  ..., -8.3078e-03,\n",
       "           6.3368e-02,  1.2328e-01],\n",
       "         ...,\n",
       "         [ 5.1315e-02, -4.3455e-01, -1.0332e-01,  ...,  2.9795e-02,\n",
       "          -5.7426e-02, -1.7541e-04],\n",
       "         [ 2.6858e-02, -4.4956e-01, -1.2668e-01,  ...,  5.7979e-02,\n",
       "          -2.2074e-01, -4.7746e-02],\n",
       "         [-1.1459e-01,  3.6559e-02, -1.0911e-01,  ..., -6.2565e-02,\n",
       "          -1.8362e-01,  7.9108e-02]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "         [-0.4367,  0.5360, -0.0514,  ..., -0.0397,  0.6783, -0.5318],\n",
       "         [ 0.7838, -0.3506, -1.1582,  ..., -0.8033,  0.1465,  0.2171],\n",
       "         ...,\n",
       "         [ 0.2022,  0.0762,  0.3220,  ...,  0.5130, -0.6300, -0.0597],\n",
       "         [ 1.3539,  0.4626,  0.3129,  ..., -0.9238, -0.9422, -0.4833],\n",
       "         [ 0.7480,  0.4874, -0.3261,  ..., -0.5679,  0.9606, -1.7922]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABert(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.m2 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.embeddings = self.m1.embeddings\n",
    "        self.ga = GatedAttention()\n",
    "        \n",
    "        \n",
    "    def forward(self, article_tokens, question_tokens, options_tokens, article_attention_mask=None, question_attention_mask=None):\n",
    "        article_embeds = self.embeddings(article_tokens)\n",
    "        question_embeds = self.embeddings(question_tokens)\n",
    "        options_embeds = self.embeddings(options_tokens)\n",
    "        \n",
    "        question_contexts = question_embeds\n",
    "        article_contexts = article_embeds\n",
    "        \n",
    "        for i in range(len(self.m1.encoder.layer)):\n",
    "            current_layer_1 = self.m1.encoder.layer[i]\n",
    "            current_layer_2 = self.m2.encoder.layer[i]\n",
    "            question_contexts = current_layer_1(question_contexts, question_attention_mask)[0]\n",
    "            article_intermediates = current_layer_2(article_contexts, article_attention_mask)[0]\n",
    "            article_contexts = ga(question_contexts,article_intermediates)\n",
    "        return question_contexts,article_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabert = GABert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2625,  0.1005,  0.5384,  ..., -0.2146,  0.1149,  0.2406],\n",
       "          [ 0.4076, -0.0331,  0.6515,  ..., -0.4912, -0.0818, -0.2506],\n",
       "          [ 1.0710, -0.0842,  0.7467,  ..., -0.4354, -0.1184, -0.0889],\n",
       "          ...,\n",
       "          [ 0.3348, -0.5068,  0.6650,  ...,  0.3952,  0.4215, -0.4632],\n",
       "          [ 0.4878,  0.5904,  0.0101,  ..., -0.0534, -0.7088, -0.1635],\n",
       "          [ 0.1715,  0.4857,  0.2637,  ...,  0.1968, -0.8782, -0.2744]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[[ 8.1008e-02,  8.4509e-02,  9.0809e-02,  ..., -2.0987e-02,\n",
       "            2.0178e-02,  1.3246e-01],\n",
       "          [ 7.2911e-02,  5.7018e-02,  7.9535e-02,  ..., -1.7414e-02,\n",
       "            4.2224e-02,  1.2953e-01],\n",
       "          [ 6.1251e-02,  2.1614e-02,  7.0671e-02,  ..., -8.3078e-03,\n",
       "            6.3368e-02,  1.2328e-01],\n",
       "          ...,\n",
       "          [ 5.1315e-02, -4.3455e-01, -1.0332e-01,  ...,  2.9795e-02,\n",
       "           -5.7426e-02, -1.7541e-04],\n",
       "          [ 2.6858e-02, -4.4956e-01, -1.2668e-01,  ...,  5.7979e-02,\n",
       "           -2.2074e-01, -4.7746e-02],\n",
       "          [-1.1459e-01,  3.6559e-02, -1.0911e-01,  ..., -6.2565e-02,\n",
       "           -1.8362e-01,  7.9108e-02]]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabert(article_token,question_token,options_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
