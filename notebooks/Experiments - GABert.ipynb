{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gc\n",
    "import torch\n",
    "from transformers import BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_options(options_tensor,func):\n",
    "    single_option_shape = list(options_tensor.shape)\n",
    "    single_option_shape[1]=1\n",
    "    return torch.cat([func(torch.gather(options_tensor,1,torch.ones(single_option_shape,dtype=torch.int64)*i)) for i in range(5)],dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedAttention(torch.nn.Module):      \n",
    "    def forward(self, question_states, article_states):\n",
    "        question_att = question_states.permute(0,2,1)\n",
    "        att_matrix = torch.bmm(article_states,question_att)\n",
    "        \n",
    "        att_weights = torch.nn.functional.softmax(att_matrix.view(-1,att_matrix.size(-1)),dim=1).view_as(att_matrix)\n",
    "        question_rep = torch.bmm(att_weights, question_states)\n",
    "    \n",
    "        question_to_article = torch.mul(article_states, question_rep)\n",
    "        \n",
    "        return question_to_article ##Attention applied on articles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertEmbeddings(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = BertModel.from_pretrained('bert-base-uncased').embeddings\n",
    "    \n",
    "    def forward(self, article_tokens, question_tokens, options_tokens):\n",
    "        article_embeds = self.embeddings(article_tokens)\n",
    "        question_embeds = self.embeddings(question_tokens)\n",
    "        options_embeds = process_options(options_tokens,self.embeddings)\n",
    "    \n",
    "        return article_embeds, question_embeds, options_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertEncoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.m2 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.ga = GatedAttention()\n",
    "        \n",
    "    def forward(self, article_contexts, question_contexts, article_attention_mask=None, question_attention_mask=None):\n",
    "        \n",
    "        for i in range(len(self.m1.encoder.layer)):\n",
    "            current_layer_1 = self.m1.encoder.layer[i]\n",
    "            current_layer_2 = self.m2.encoder.layer[i]\n",
    "            question_contexts = current_layer_1(question_contexts, question_attention_mask.unsqueeze(1).unsqueeze(3))[0]\n",
    "#             print(question_contexts.shape)\n",
    "            article_intermediates = current_layer_2(article_contexts, article_attention_mask.unsqueeze(1).unsqueeze(3))[0]\n",
    "#             print(article_intermediates.shape)\n",
    "            article_contexts = self.ga(question_contexts,article_intermediates)\n",
    "        \n",
    "        return article_contexts, question_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertPooler(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pooler = BertModel.from_pretrained('bert-base-uncased').pooler\n",
    "    def forward(self,contexts):\n",
    "        return self.pooler(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Layer Out (Baseline GAReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        torch.nn.init.kaiming_normal_(self.linear.weight.data)\n",
    "        torch.nn.init.constant_(self.linear.bias.data, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x: [batch_size, seq_len, in_features]\n",
    "        x = self.linear(x)\n",
    "        # x: [batch_size, seq_len, out_features]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAttention(torch.nn.Module):\n",
    "    def __init__(self, dim, dropout):\n",
    "        super(MLPAttention, self).__init__()\n",
    "\n",
    "        self.Q_W = Linear(dim, dim)\n",
    "        self.K_W = Linear(dim, dim)\n",
    "        self.V_W = Linear(dim, dim)\n",
    "\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.V = Linear(dim, 1)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        # Q: [batch_size, dim]\n",
    "        # K: [batch_size, seq_len, dim]\n",
    "        # V: [batch_size, seq_len, dim]\n",
    "        \n",
    "#         print(Q)\n",
    "#         print(K)\n",
    "#         print(V)\n",
    "\n",
    "        Q = self.dropout(self.Q_W(Q))  # [batch_size, dim]\n",
    "        K = self.dropout(self.K_W(K))  # [batch_size, seq_len, dim]\n",
    "        V = self.dropout(self.V_W(V))  # [batch_size, seq_len, dim]\n",
    "\n",
    "        Q = Q.unsqueeze(1)  # [batch_size, 1, dim]\n",
    "        M = self.dropout(self.tanh(Q + K))  # [batch_size, seq_len, dim]\n",
    "        scores = self.dropout(self.V(M))  # [batch_size, seq_len, 1]\n",
    "        scores = torch.nn.functional.softmax(scores, dim=1)  # [batch_size, seq_len, 1]\n",
    "\n",
    "        R = self.dropout(V * scores)  # [batch_size, seq_len, dim]\n",
    "\n",
    "        feat = torch.sum(R, dim=1)  # [batch_size, dim]\n",
    "\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineOut(torch.nn.Module):\n",
    "    def __init__(self,dropout, hidden_size, output_dim):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.mlp_att = MLPAttention(hidden_size, dropout)\n",
    "        self.dot_layer = MLPAttention(hidden_size,dropout)\n",
    "        self.final_linear = Linear(hidden_size*5,output_dim)\n",
    "    def forward(self, article_contexts,question_contexts,options_embeds, answer_indices):\n",
    "        \n",
    "        single_question_context_shape = list(question_contexts.shape)\n",
    "        single_question_context_shape[1] = 1 \n",
    "        \n",
    "    \n",
    "        ## Get the context for answer indices\n",
    "        ## CAN ALSO GET JUST THE FIRST OUTPUT\n",
    "        overall_question_context = torch.gather(question_contexts,1,torch.ones(single_question_context_shape,dtype=torch.int64)*answer_indices.reshape(-1,1,1)).squeeze(1)\n",
    "        article_question_attention = self.mlp_att(overall_question_context, article_contexts, article_contexts)\n",
    "        \n",
    "#         print(article_question_attention.shape)\n",
    "        \n",
    "        options_attentions = process_options(options_embeds,lambda x: self.dropout(self.dot_layer(article_question_attention,x.squeeze(1),x.squeeze(1))))\n",
    "        \n",
    "\n",
    "        logits = self.dropout(self.final_linear(options_attentions))\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection and Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertPredictionHeadTransform(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = torch.nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.transform_act_fn = (\n",
    "            ACT2FN[config.hidden_act]\n",
    "            if isinstance(config.hidden_act, str)\n",
    "            else config.hidden_act\n",
    "        )\n",
    "        self.LayerNorm = torch.nn.LayerNorm(config.hidden_size,eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertLMPredictionHead(torch.nn.Module):\n",
    "    def __init__(self, config, model_embedding_weights):\n",
    "        super().__init__()\n",
    "        self.transform = GABertPredictionHeadTransform(config)\n",
    "\n",
    "        # The output weights are the same as the input embeddings, but there is\n",
    "        # an output-only bias for each token.\n",
    "        self.decoder = torch.nn.Linear(\n",
    "            model_embedding_weights.size(1),\n",
    "            model_embedding_weights.size(0),\n",
    "            bias=False,\n",
    "        )\n",
    "        self.decoder.weight = model_embedding_weights\n",
    "        self.bias = torch.nn.Parameter(\n",
    "            torch.zeros(model_embedding_weights.size(0))\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.transform(hidden_states)\n",
    "\n",
    "        hidden_states = self.decoder(hidden_states) + self.bias\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClozeStyleOut(torch.nn.Module):\n",
    "    def __init__(self,embeddings):\n",
    "        super().__init__()\n",
    "        bc = BertConfig.from_pretrained('bert-base-uncased')\n",
    "        self.cls = GABertLMPredictionHead(bc,embeddings.word_embeddings.weight)\n",
    "        self.vocab_size = embeddings.word_embeddings.weight.size(0)\n",
    "        self.pad_token_id = bc.pad_token_id\n",
    "    def forward(self, question_contexts,options_tokens, answer_indices):\n",
    "        \n",
    "        bsz = options_tokens.size(0)\n",
    "        options_tokens = options_tokens.reshape(bsz,1,5,-1)\n",
    "        opnum = options_tokens.size(1)\n",
    "        \n",
    "        \n",
    "        ### CAN ALSO REPLACE WITH CODE IN LONGFORMERS_CLOZE\n",
    "        single_question_context_shape = list(question_contexts.shape)\n",
    "        single_question_context_shape[1] = 1 \n",
    "        out = torch.gather(question_contexts,1,torch.ones(single_question_context_shape,dtype=torch.int64)*answer_indices.reshape(-1,1,1))\n",
    "        \n",
    "        out = self.cls(out)\n",
    "        \n",
    "        out = out.view(bsz,opnum,1,self.vocab_size)\n",
    "        out[:, :, :, self.pad_token_id] = 0\n",
    "        out = out.expand(bsz, opnum, 5, self.vocab_size)\n",
    "        \n",
    "        out_tokens = torch.zeros((bsz, opnum, 5, 1), device=options_tokens.device)\n",
    "        pad_tokens = options_tokens.shape[3] - torch.sum((options_tokens == self.pad_token_id), dim=3).unsqueeze(3)\n",
    "        \n",
    "        for i in range(options_tokens.shape[3]):\n",
    "            ops_token = options_tokens[:, :, :, i].unsqueeze(3)\n",
    "            out_tokens += torch.gather(out, 3, ops_token)\n",
    "\n",
    "        out_tokens = torch.div(out_tokens, pad_tokens)\n",
    "        out = out_tokens\n",
    "        out = out.view(-1, 5)\n",
    "\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABert(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = GABertEmbeddings()\n",
    "        self.encoder = GABertEncoder()\n",
    "    def forward(self,article_tokens, question_tokens, options_tokens, article_attention_masks=None, question_attention_masks = None):\n",
    "        article_embeds, question_embeds, options_embeds = self.embeddings(article_tokens,question_tokens, options_tokens)\n",
    "        article_contexts, question_contexts= self.encoder(article_embeds, question_embeds, article_attention_masks, question_attention_masks)\n",
    "        \n",
    "        return article_contexts, question_contexts, options_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "##UNUSED\n",
    "class GABertModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gabert = GABert()\n",
    "\n",
    "        self.question_pooler = GABertPooler()\n",
    "        self.article_pooler = GABertPooler()\n",
    "        \n",
    "    def forward(self,article_tokens, question_tokens, options_tokens, article_attention_masks=None, question_attention_masks = None):\n",
    "        article_contexts, question_contexts, options_embeds = self.gabert(article_tokens, question_tokens,options_tokens, article_attention_masks, question_attention_masks)\n",
    "        \n",
    "        #all_contexts = torch.cat([article_contexts,question_contexts],dim=1)\n",
    "        \n",
    "        #return self.pooler(all_contexts)\n",
    "        return article_contexts, question_contexts, options_embeds, self.article_pooler(article_contexts), self.question_pooler(question_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABertCloze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertCloze(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = GABert()\n",
    "        self.cloze_out = ClozeStyleOut(self.model.embeddings.embeddings)\n",
    "    def forward(self, batch):\n",
    "        article_contexts, question_contexts,options_embeds = self.model(batch['articles_token_ids'], batch['questions_token_ids'], batch['options_token_ids'], batch['articles_attention_mask'], batch['questions_attention_mask'])       \n",
    "        cloze_logits = self.cloze_out(question_contexts,batch['options_token_ids'],batch['answer_indices'])\n",
    "        return cloze_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABertQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertQA(torch.nn.Module):\n",
    "    def __init__(self,dropout, hidden_size, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = GABert()\n",
    "        self.qa_out = BaselineOut(dropout, hidden_size,output_dim)\n",
    "    def forward(self, batch):\n",
    "        article_contexts, question_contexts,options_embeds = self.model(batch['articles_token_ids'], batch['questions_token_ids'], batch['options_token_ids'], batch['articles_attention_mask'], batch['questions_attention_mask'])\n",
    "        qa_logits =  self.qa_out(article_contexts,question_contexts,options_embeds,batch['answer_indices'])\n",
    "        return qa_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABertClozeAndQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertClozeAndQA(torch.nn.Module):\n",
    "    def __init__(self,dropout, hidden_size, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = GABert()\n",
    "        self.qa_out = BaselineOut(dropout, hidden_size,output_dim)\n",
    "        self.cloze_out = ClozeStyleOut(self.model.embeddings.embeddings)\n",
    "        self.linear = torch.nn.Linear(output_dim*2,output_dim)\n",
    "    def forward(self, batch):\n",
    "        article_contexts, question_contexts,options_embeds = self.model(batch['articles_token_ids'], batch['questions_token_ids'], batch['options_token_ids'], batch['articles_attention_mask'], batch['questions_attention_mask'])\n",
    "         \n",
    "        qa_logits =  self.qa_out(article_contexts,question_contexts,options_embeds,batch['answer_indices'])\n",
    "        cloze_logits = self.cloze_out(question_contexts,batch['options_token_ids'],batch['answer_indices'])\n",
    "        \n",
    "        concat = torch.cat([qa_logits,cloze_logits],dim=1)\n",
    "        return self.linear(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze_qa = GABertClozeAndQA(0.2,768,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReCAMDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ReCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_1_FILE = './data/train/Task_1_train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.mapper import configmapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'file_path': TRAIN_1_FILE,\n",
    "    'tokenizer':{\n",
    "        'name': 'BertTokenizer',\n",
    "        'init_params':\n",
    "        {'pretrained_model_name_or_path': 'bert-base-uncased'}\n",
    "    },\n",
    "    'split':'train',\n",
    "    'article_truncate_length':512,\n",
    "    'question_truncate_length':512,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.configuration import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = Config(dic=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(dic={'file_path': './data/train/Task_1_train.jsonl', 'tokenizer': {'name': 'BertTokenizer', 'init_params': {'pretrained_model_name_or_path': 'bert-base-uncased'}}, 'split': 'train', 'article_truncate_length': 512, 'question_truncate_length': 512})"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.tokenizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = configmapper.get_object('tokenizers',data_config.tokenizer.name).from_pretrained(**data_config.tokenizer.init_params.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReCAMDataset(Dataset):\n",
    "    def __init__(self,config,tokenizer):\n",
    "        self.config = config\n",
    "        self.tokenizer = tokenizer\n",
    "        with jsonlines.open(self.config.file_path) as f:\n",
    "            self.data = list(f)\n",
    "        self.mask_id = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "        self.pad_id = self.tokenizer.convert_tokens_to_ids(self.tokenizer.pad_token)\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _preprocess(self,data):\n",
    "        article = data['article'].lower()\n",
    "        question = data['question'].lower().replace('@placeholder',self.tokenizer.mask_token)\n",
    "        \n",
    " \n",
    "        article_token_ids = self.tokenizer.encode(article)\n",
    "        question_token_ids = self.tokenizer.encode(question)\n",
    "        answer_index = question_token_ids.index(self.mask_id)\n",
    "        \n",
    "           \n",
    "        article_token_ids = article_token_ids[:self.config.article_truncate_length]\n",
    "        beg = max(0,answer_index-(self.config.question_truncate_length/2))\n",
    "        end = min(len(question_token_ids),answer_index+(self.config.question_truncate_length/2))\n",
    " \n",
    "        ## Need answer_index in the center if max_length exceeds the total length\n",
    "        question_token_ids = question_token_ids[beg:end]\n",
    "        answer_index = question_token_ids.index(self.mask_id) ## Fix answer index again\n",
    "     \n",
    "        options_token_ids = [self.tokenizer.encode(data[f'option_{i}'].lower()) for i in range(5)]\n",
    "        \n",
    "        answer = data['label']\n",
    "        \n",
    "        return {\n",
    "            \"article_token_ids\":article_token_ids,\n",
    "            \"question_token_ids\":question_token_ids,\n",
    "            \"options_token_ids\":options_token_ids,\n",
    "            \"label\": answer,\n",
    "            \"answer_index\":answer_index,\n",
    "        }\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return_dic = self._preprocess(self.data[idx])\n",
    "#         return_dic[\"article_attention_mask\"] = [1]*len(return_dic[\"article_token_ids\"])\n",
    "#         return_dic[\"question_attention_mask\"] = [1]*len(return_dic[\"question_token_ids\"])\n",
    "        return_dic[\"article_attention_mask\"] = [1]*len(return_dic[\"article_token_ids\"])\n",
    "        return_dic[\"question_attention_mask\"] = [1]*len(return_dic[\"question_token_ids\"])\n",
    "        \n",
    "        return return_dic\n",
    "    \n",
    "    def custom_collate_fn(self, batch):\n",
    "        max_article_len = 0\n",
    "        max_question_len = 0\n",
    "        max_options_len = 0\n",
    "        \n",
    "        articles = []\n",
    "        article_masks = []\n",
    "        questions = []\n",
    "        question_masks = []\n",
    "        answer_indices = []\n",
    "        options = []\n",
    "        labels = []\n",
    "        \n",
    "        for sample in batch:\n",
    "            max_article_len = max(max_article_len, len(sample[\"article_token_ids\"]))\n",
    "            max_question_len = max(max_question_len, len(sample[\"question_token_ids\"]))\n",
    "            max_options_len = max(max_options_len, max([len(i) for i in sample[\"options_token_ids\"]]))\n",
    "            \n",
    "            articles.append(sample['article_token_ids'])\n",
    "            questions.append(sample['question_token_ids'])\n",
    "            article_masks.append(sample['article_attention_mask'])\n",
    "            question_masks.append(sample['question_attention_mask'])\n",
    "            answer_indices.append(sample['answer_index'])\n",
    "            options.append(sample['options_token_ids'])\n",
    "            labels.append(sample['label'])\n",
    "            \n",
    "        for i in range(len(articles)):\n",
    "            articles[i]= articles[i] + [self.pad_id]*(max_article_len - len(articles[i]))\n",
    "            questions[i]= questions[i] + [self.pad_id]*(max_question_len - len(questions[i]))   \n",
    "            article_masks[i]= article_masks[i] + [self.pad_id]*(max_article_len - len(article_masks[i]))\n",
    "            question_masks[i]= question_masks[i] + [self.pad_id]*(max_question_len - len(question_masks[i]))\n",
    "            for option_index in range(len(options[i])):\n",
    "                options[i][option_index] = options[i][option_index] + [self.pad_id]*(max_options_len -len(options[i][option_index]))\n",
    "        \n",
    "        return {\n",
    "            'articles_token_ids':torch.LongTensor(articles),\n",
    "            'questions_token_ids':torch.LongTensor(questions),\n",
    "            'options_token_ids':torch.LongTensor(options),\n",
    "            'answer_indices':torch.LongTensor(answer_indices),\n",
    "            'articles_attention_mask':torch.FloatTensor(article_masks),\n",
    "            'questions_attention_mask':torch.FloatTensor(question_masks),\n",
    "            'labels':torch.LongTensor(labels)  \n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "recam = ReCAMDataset(data_config,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "recam_loader = DataLoader(recam,batch_size=4,shuffle=True,collate_fn=recam.custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(recam_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6879,  0.9881,  0.1863, -1.1397, -0.9088],\n",
       "        [ 0.3998, -0.8709,  0.9386, -1.0847, -1.5621],\n",
       "        [-1.2080, -0.5134,  2.1246, -0.9045, -2.0161],\n",
       "        [-0.8349,  0.7174,  1.8829, -1.7672, -0.3401]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloze_qa(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
