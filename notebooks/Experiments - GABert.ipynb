{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gc\n",
    "import torch\n",
    "from transformers import BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_1_FILE = '../data/train/Task_1_train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_1_FILE,'r') as f:\n",
    "    lines = [json.loads(line) for line in f.read().splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "bt = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "article_token = bt.encode(example['article'])[:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_token = bt.encode(example['question'].replace('@placeholder','[MASK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_id = bt.convert_tokens_to_ids('[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_tokens = [bt.encode(example[f'option_{i}']) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_token = torch.LongTensor([article_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_token = torch.LongTensor([question_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_tokens = torch.LongTensor(options_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_tokens = options_tokens.reshape(1,5,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_indices = torch.nonzero(question_token==mask_id,as_tuple=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_indices = answer_indices.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_tokens = options_tokens.reshape(1,5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_options(options_tensor,func):\n",
    "    single_option_shape = list(options_tensor.shape)\n",
    "    single_option_shape[1]=1\n",
    "    return torch.cat([func(torch.gather(options_tensor,1,torch.ones(single_option_shape,dtype=torch.int64)*i)) for i in range(5)],dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedAttention(torch.nn.Module):      \n",
    "    def forward(self, question_states, article_states):\n",
    "        question_att = question_states.permute(0,2,1)\n",
    "        att_matrix = torch.bmm(article_states,question_att)\n",
    "        \n",
    "        att_weights = torch.nn.functional.softmax(att_matrix.view(-1,att_matrix.size(-1)),dim=1).view_as(att_matrix)\n",
    "        question_rep = torch.bmm(att_weights, question_states)\n",
    "    \n",
    "        question_to_article = torch.mul(article_states, question_rep)\n",
    "        \n",
    "        return question_to_article ##Attention applied on articles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertEmbeddings(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = BertModel.from_pretrained('bert-base-uncased').embeddings\n",
    "    \n",
    "    def forward(self, article_tokens, question_tokens, options_tokens):\n",
    "        article_embeds = self.embeddings(article_tokens)\n",
    "        question_embeds = self.embeddings(question_tokens)\n",
    "        options_embeds = process_options(options_tokens,self.embeddings)\n",
    "    \n",
    "        return article_embeds, question_embeds, options_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GABertEmbeddings()\n",
    "article_embeds, question_embeds, options_embeds = embeddings(article_token,question_token, options_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3, 768])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertEncoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.m2 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.ga = GatedAttention()\n",
    "        \n",
    "    def forward(self, article_contexts, question_contexts, article_attention_mask=None, question_attention_mask=None):\n",
    "        \n",
    "        for i in range(len(self.m1.encoder.layer)):\n",
    "            current_layer_1 = self.m1.encoder.layer[i]\n",
    "            current_layer_2 = self.m2.encoder.layer[i]\n",
    "            question_contexts = current_layer_1(question_contexts, question_attention_mask)[0]\n",
    "#             print(question_contexts.shape)\n",
    "            article_intermediates = current_layer_2(article_contexts, article_attention_mask)[0]\n",
    "#             print(article_intermediates.shape)\n",
    "            article_contexts = self.ga(question_contexts,article_intermediates)\n",
    "        \n",
    "        return article_contexts, question_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GABertEncoder()\n",
    "article_contexts, question_contexts= encoder(article_embeds, question_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertPooler(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pooler = BertModel.from_pretrained('bert-base-uncased').pooler\n",
    "    def forward(self,contexts):\n",
    "        return self.pooler(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Layer Out (Baseline GAReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        torch.nn.init.kaiming_normal_(self.linear.weight.data)\n",
    "        torch.nn.init.constant_(self.linear.bias.data, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x: [batch_size, seq_len, in_features]\n",
    "        x = self.linear(x)\n",
    "        # x: [batch_size, seq_len, out_features]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAttention(torch.nn.Module):\n",
    "    def __init__(self, dim, dropout):\n",
    "        super(MLPAttention, self).__init__()\n",
    "\n",
    "        self.Q_W = Linear(dim, dim)\n",
    "        self.K_W = Linear(dim, dim)\n",
    "        self.V_W = Linear(dim, dim)\n",
    "\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.V = Linear(dim, 1)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        # Q: [batch_size, dim]\n",
    "        # K: [batch_size, seq_len, dim]\n",
    "        # V: [batch_size, seq_len, dim]\n",
    "        \n",
    "#         print(Q)\n",
    "#         print(K)\n",
    "#         print(V)\n",
    "\n",
    "        Q = self.dropout(self.Q_W(Q))  # [batch_size, dim]\n",
    "        K = self.dropout(self.K_W(K))  # [batch_size, seq_len, dim]\n",
    "        V = self.dropout(self.V_W(V))  # [batch_size, seq_len, dim]\n",
    "\n",
    "        Q = Q.unsqueeze(1)  # [batch_size, 1, dim]\n",
    "        M = self.dropout(self.tanh(Q + K))  # [batch_size, seq_len, dim]\n",
    "        scores = self.dropout(self.V(M))  # [batch_size, seq_len, 1]\n",
    "        scores = torch.nn.functional.softmax(scores, dim=1)  # [batch_size, seq_len, 1]\n",
    "\n",
    "        R = self.dropout(V * scores)  # [batch_size, seq_len, dim]\n",
    "\n",
    "        feat = torch.sum(R, dim=1)  # [batch_size, dim]\n",
    "\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineOut(torch.nn.Module):\n",
    "    def __init__(self,dropout, hidden_size, output_dim):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.mlp_att = MLPAttention(hidden_size, dropout)\n",
    "        self.dot_layer = MLPAttention(hidden_size,dropout)\n",
    "        self.final_linear = Linear(hidden_size*5,output_dim)\n",
    "    def forward(self, article_contexts,question_contexts,options_embeds, answers_indices):\n",
    "        \n",
    "        single_question_context_shape = list(question_contexts.shape)\n",
    "        single_question_context_shape[1] = 1 \n",
    "        \n",
    "    \n",
    "        ## Get the context for answer indices\n",
    "        ## CAN ALSO GET JUST THE FIRST OUTPUT\n",
    "        overall_question_context = torch.gather(question_contexts,1,torch.ones(single_question_context_shape,dtype=torch.int64)*answer_indices.reshape(-1,1,1)).squeeze(1)\n",
    "        article_question_attention = self.mlp_att(overall_question_context, article_contexts, article_contexts)\n",
    "        \n",
    "#         print(article_question_attention.shape)\n",
    "        \n",
    "        options_attentions = process_options(options_embeds,lambda x: self.dropout(self.dot_layer(article_question_attention,x.squeeze(1),x.squeeze(1))))\n",
    "        \n",
    "\n",
    "        logits = self.dropout(self.final_linear(options_attentions))\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo = BaselineOut(0.2,768,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_contexts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 768])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_contexts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3, 768])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -1.5368,  2.4633, -2.6659,  0.6337]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo(article_contexts, question_contexts, options_embeds, answer_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection and Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertPredictionHeadTransform(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = torch.nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.transform_act_fn = (\n",
    "            ACT2FN[config.hidden_act]\n",
    "            if isinstance(config.hidden_act, str)\n",
    "            else config.hidden_act\n",
    "        )\n",
    "        self.LayerNorm = torch.nn.LayerNorm(config.hidden_size,eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertLMPredictionHead(torch.nn.Module):\n",
    "    def __init__(self, config, model_embedding_weights):\n",
    "        super().__init__()\n",
    "        self.transform = GABertPredictionHeadTransform(config)\n",
    "\n",
    "        # The output weights are the same as the input embeddings, but there is\n",
    "        # an output-only bias for each token.\n",
    "        self.decoder = torch.nn.Linear(\n",
    "            model_embedding_weights.size(1),\n",
    "            model_embedding_weights.size(0),\n",
    "            bias=False,\n",
    "        )\n",
    "        self.decoder.weight = model_embedding_weights\n",
    "        self.bias = torch.nn.Parameter(\n",
    "            torch.zeros(model_embedding_weights.size(0))\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.transform(hidden_states)\n",
    "\n",
    "        hidden_states = self.decoder(hidden_states) + self.bias\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClozeStyleOut(torch.nn.Module):\n",
    "    def __init__(self,embeddings):\n",
    "        super().__init__()\n",
    "        bc = BertConfig.from_pretrained('bert-base-uncased')\n",
    "        self.cls = GABertLMPredictionHead(bc,embeddings.word_embeddings.weight)\n",
    "        self.vocab_size = embeddings.word_embeddings.weight.size(0)\n",
    "        self.pad_token_id = bc.pad_token_id\n",
    "    def forward(self, question_contexts,options_tokens, answers_indices):\n",
    "        \n",
    "        bsz = options_tokens.size(0)\n",
    "        options_tokens = options_tokens.reshape(bsz,1,5,-1)\n",
    "        opnum = options_tokens.size(1)\n",
    "        \n",
    "        \n",
    "        ### CAN ALSO REPLACE WITH CODE IN LONGFORMERS_CLOZE\n",
    "        single_question_context_shape = list(question_contexts.shape)\n",
    "        single_question_context_shape[1] = 1 \n",
    "        out = torch.gather(question_contexts,1,torch.ones(single_question_context_shape,dtype=torch.int64)*answer_indices.reshape(-1,1,1))\n",
    "        \n",
    "        out = self.cls(out)\n",
    "        \n",
    "        out = out.view(bsz,opnum,1,self.vocab_size)\n",
    "        out[:, :, :, self.pad_token_id] = 0\n",
    "        out = out.expand(bsz, opnum, 5, self.vocab_size)\n",
    "        \n",
    "        out_tokens = torch.zeros((bsz, opnum, 5, 1), device=options_tokens.device)\n",
    "        pad_tokens = options_tokens.shape[3] - torch.sum((options_tokens == self.pad_token_id), dim=3).unsqueeze(3)\n",
    "        \n",
    "        for i in range(options_tokens.shape[3]):\n",
    "            ops_token = options_tokens[:, :, :, i].unsqueeze(3)\n",
    "            out_tokens += torch.gather(out, 3, ops_token)\n",
    "\n",
    "        out_tokens = torch.div(out_tokens, pad_tokens)\n",
    "        out = out_tokens\n",
    "        out = out.view(-1, 5)\n",
    "\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BertModel.from_pretrained('bert-base-uncased')\n",
    "cso = ClozeStyleOut(m.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2714, -0.0638, -0.7544, -0.2383, -0.4498]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cso(question_contexts,options_tokens,answer_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABert(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = GABertEmbeddings()\n",
    "        self.encoder = GABertEncoder()\n",
    "    def forward(self,article_tokens, question_tokens, options_tokens, article_attention_masks=None, question_attention_masks = None):\n",
    "        article_embeds, question_embeds, options_embeds = self.embeddings(article_token,question_token, options_tokens)\n",
    "        article_contexts, question_contexts= self.encoder(article_embeds, question_embeds, article_attention_masks, question_attention_masks)\n",
    "        \n",
    "        return article_contexts, question_contexts, options_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "##UNUSED\n",
    "class GABertModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gabert = GABert()\n",
    "\n",
    "        self.question_pooler = GABertPooler()\n",
    "        self.article_pooler = GABertPooler()\n",
    "        \n",
    "    def forward(self,article_tokens, question_tokens, options_tokens, article_attention_masks=None, question_attention_masks = None):\n",
    "        article_embeds, question_embeds, options_embeds = self.embeddings(article_token,question_token, options_tokens)\n",
    "        article_contexts, question_contexts= self.encoder(article_embeds, question_embeds, article_attention_masks, question_attention_masks)\n",
    "        \n",
    "        #all_contexts = torch.cat([article_contexts,question_contexts],dim=1)\n",
    "        \n",
    "        #return self.pooler(all_contexts)\n",
    "        print(article_contexts.shape)\n",
    "        return article_contexts, question_contexts, self.article_pooler(article_contexts), self.question_pooler(question_contexts), options_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gabert = GABertModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "gabert_outs = gabert(article_token, question_token,options_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabert_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabert_outs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3, 768])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabert_outs[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABertCloze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertCloze(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = GABert()\n",
    "        self.cloze_out = ClozeStyleOut(self.model.embeddings.embeddings)\n",
    "    def forward(self, batch):\n",
    "        article_tokens, question_tokens, options_tokens, answer_indices,article_attention_masks,question_attention_masks = batch\n",
    "        article_contexts, question_contexts,options_embeds = self.model(article_tokens, question_tokens, options_tokens, article_attention_masks, question_attention_masks)\n",
    "        \n",
    "        return self.cloze_out(question_contexts,options_tokens,answer_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = (article_token,question_token,options_tokens,answer_indices,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze = GABertCloze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2335, -1.3469, -1.8909, -1.4368, -1.3653]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloze(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6490"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABertQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertQA(torch.nn.Module):\n",
    "    def __init__(self,dropout, hidden_size, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = GABert()\n",
    "        self.qa_out = BaselineOut(dropout, hidden_size,output_dim)\n",
    "    def forward(self, batch):\n",
    "        article_tokens, question_tokens, options_tokens, answer_indices,article_attention_masks,question_attention_masks = batch\n",
    "        article_contexts, question_contexts,options_embeds = self.model(article_tokens, question_tokens, options_tokens, article_attention_masks, question_attention_masks)\n",
    "         \n",
    "        return self.qa_out(article_contexts,question_contexts,options_embeds,answer_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = GABertQA(0.2,768,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -2.9447, -1.3406, -1.3167, -0.1524]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABertClozeAndQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GABertClozeAndQA(torch.nn.Module):\n",
    "    def __init__(self,dropout, hidden_size, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = GABert()\n",
    "        self.qa_out = BaselineOut(dropout, hidden_size,output_dim)\n",
    "        self.cloze_out = ClozeStyleOut(self.model.embeddings.embeddings)\n",
    "        self.linear = torch.nn.Linear(output_dim*2,output_dim)\n",
    "    def forward(self, batch):\n",
    "        article_tokens, question_tokens, options_tokens, answer_indices,article_attention_masks,question_attention_masks = batch\n",
    "        article_contexts, question_contexts,options_embeds = self.model(article_tokens, question_tokens, options_tokens, article_attention_masks, question_attention_masks)\n",
    "         \n",
    "        qa_logits =  self.qa_out(article_contexts,question_contexts,options_embeds,answer_indices)\n",
    "        cloze_logits = self.cloze_out(question_contexts,options_tokens,answer_indices)\n",
    "        \n",
    "        concat = torch.cat([qa_logits,cloze_logits],dim=1)\n",
    "        return self.linear(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze_qa = GABertClozeAndQA(0.2,768,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1695, -1.1336,  0.1333,  1.7995,  0.9574]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloze_qa(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
