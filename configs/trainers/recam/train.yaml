trainer_name: gabert
version: 1.0
main_config: &main
    seed: !!int 42
    metrics:
      - type: sklearn_f1
        params:
          average: macro
          labels:
            - !!int 0
            - !!int 1
            - !!int 2
            - !!int 3
            - !!int 4

      - type: sklearn_p
        params:
          average: macro
          labels:
            - !!int 0
            - !!int 1
            - !!int 2
            - !!int 3
            - !!int 4

      - type: sklearn_r
        params:
          average: macro
          labels:
            - !!int 0
            - !!int 1
            - !!int 2
            - !!int 3
            - !!int 4

      - type: sklearn_acc
        params:
          normalize: true

    device:
        name: 'cuda'

train: &train
    # Change to different value if not using max_steps
    <<: *main
    # Can add the max_epochs vs max_steps functionality
    label_type: long
    append_text: train
    max_epochs: !!int 10
    loader_params:
        batch_size: !!int 8
        num_workers: !!int 4
        shuffle: true

    optimizer:
        type: adam_w
        params:
            lr: !!float 1e-5
            betas: [0.9,0.998]
            eps: !!float 1e-8

    scheduler: null

    criterion:
        type: CrossEntropyLoss
        params: null

    save_on : ##Best Model/Final Model Saving
      score: sklearn_acc
      desired: min
      best_path: './ckpts/recam/train/best_{}.pth'
      final_path: './ckpts/recam/train/final_{}.pth'
    save_after_epoch: false


    checkpoint:
        checkpoint_dir: './ckpts/recam/'

    log_and_val_interval: !!int 500 ## Set to null if using different val and log intervals, Overrides log_interval nd val_interval

    val_interval: !!int 500 # Global steps
    log:
        log_interval: !!int 100 # Global Steps
        logger_params:
            model: gabertclozeqa2
            trainer: gabert
            comment: "Training GABert ClozeQA"
            log_dir: './logs/'
        log_label: 1
        values:
            loss: True
            metrics: True
            hparams: null

val:
    <<: *main
    append_text: val
    max_steps: null
    loader_params:
        batch_size: !!int 8
        num_workers: !!int 4
        shuffle: false

grid_search:
  directory: null
  hyperparams:
    train:
      max_epochs: !!int 10
      optimizer:
        type:
          - adam_w
          - adam

      scheduler:
          - null
          - type: cyclic
            params:
              base_lr: !!float 1e-7
              max_lr: !!float 1e-3
              step_size_up: !!int 20
              step_size_down: !!int 40
              mode: exp_range
              cycle_momentum: false

          - type: cosineannealrestart
            params:
              T_0: !!int 40
              T_mult: !!int 2
              eta_min: !!float 1e-9

      log:
        logger_params:
          model: gabertclozeqa2
          trainer: gabert
          comment: "GridSearch for GABert"
          log_dir: './logs/gridsearch/'
        log_label: null
        values:
          hparams:  ## Can have lists inside hparams
             - name: scheduler_type
               path:
                  - train
                  - scheduler
                  - type
             - name: scheduler_params
               path:
                  - train
                  - scheduler
                  - params
             - name: batch_size
               path:
                  - train
                  - loader_params
                  - batch_size
             - name: optimizer_params
               path:
                 - train
                 - optimizer
                 - params
             - name: optimizer_type
               path:
                 - train
                 - optimizer
                 - type
