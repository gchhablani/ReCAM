trainer_name: base
version: 1.0
main_config: &main
    seed: !!int 42
    metrics:
        - sklearn_mse
    device:
        name: 'cuda:0'

train: &train
    # Change to different value if not using max_steps
    <<: *main
    # Can add the max_epochs vs max_steps functionality
    append_text: train
    label_type: float
    max_epochs: !!int 10
    loader_params:
        batch_size: !!int 32
        num_workers: !!int 4
        shuffle: true

    optimizer:
        type: adam_w
        params:
            lr: !!float 1e-5
            betas: [0.9,0.998]
            eps: !!float 1e-8

    scheduler: null

    criterion:
        type: mse
        params: null

    save_on : ##Best Model/Final Model Saving
      score: mse
      desired: min
      best_path: './ckpts/forty/train/best_{}.pth'
      final_path: './ckpts/forty/train/final_{}.pth'

    save_after_epoch: false

    checkpoint:
        checkpoint_dir: './ckpts/forty/'

    log_and_val_interval: !!int 100 # Set to null if using different val and log intervals, Overrides log_interval nd val_interval

    val_interval: !!int 100 # Global steps
    log:
        log_interval: !!int 100 # Global Steps
        logger_params:
            model: two_layer_nn
            trainer: forty
            comment: "Trial for Logger and Trainer"
            log_dir: './logs/'
        log_label: 1
        values:
            loss: true
            metrics: true
            hparams: null

val:
    <<: *main
    append_text: val
    max_steps: null
    loader_params:
        batch_size: !!int 32
        num_workers: !!int 4
        shuffle: false

grid_search:
  directory: null
  hyperparams:
    train:
      max_epochs: !!int 10
      loader_params:
        batch_size:
          - !!int 32
          - !!int 64
          # - !!int 128
      optimizer:
        type:
          - adam_w
          - adam
        params:
          lr:
            - !!float 1e-4
            - !!float 1e-5

      scheduler:
          - null

          - type: reduceplateau
            params:
              mode: min
              factor: !!float 0.1
              patience: !!float 3

          - type: cyclic
            params:
              base_lr: !!float 1e-7
              max_lr: !!float 1e-3
              step_size_up: !!int 100
              step_size_down: !!int 200
              mode: exp_range
              cycle_momentum: false

          - type: cosineannealrestart
            params:
              T_0: !!int 100
              T_mult: !!int 2
              eta_min: !!float 1e-9

      log:
        logger_params:
          model: two_layer_nn
          trainer: forty
          comment: "GridSearch for Forty"
          log_dir: './logs/gridsearch'
        log_label: null
        values:
          hparams:  ## Can have lists inside hparams
             - name: scheduler_type
               path:
                  - train
                  - scheduler
                  - type
             - name: scheduler_params
               path:
                  - train
                  - scheduler
                  - params
             - name: batch_size
               path:
                  - train
                  - loader_params
                  - batch_size
             - name: optimizer_params
               path:
                 - train
                 - optimizer
                 - params
             - name: optimizer_type
               path:
                 - train
                 - optimizer
                 - type
